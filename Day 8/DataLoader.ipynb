{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2fe9292",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c6f993f",
   "metadata": {},
   "source": [
    "###### For this example we will work on the CIFAR10 dataset. To download this dataset we will simply call datasets.CIFAR10(). For the arguments we pass in the path where to store the dataset, a boolean value if it is for training or testing and also if we want to download the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54de84f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "data_path = 'C:\\\\Users\\\\HM\\\\Downloads\\\\Datasets\\\\'\n",
    "cifar10_train = datasets.CIFAR10(data_path, train=True, download=True)\n",
    "cifar10_val = datasets.CIFAR10(data_path, train=False, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb01dfc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cifar10_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f34fddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "image,label =cifar10_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c204e5f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PIL.Image.Image"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24b9a1a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "57c21bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes =['airplanes', 'cars', 'birds', 'cats', 'deer', 'dogs', 'frogs', 'horses', 'ships', 'trucks']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b6c13b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frogs\n"
     ]
    }
   ],
   "source": [
    "print(classes[label])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52658863",
   "metadata": {},
   "source": [
    "#### Next we will use plt.imshow(image) to see image but as kernal crashes we are not doing it here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c98e498",
   "metadata": {},
   "source": [
    "###### As we have to train our neural network we have to transform our images to tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9e583b07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AugMix',\n",
       " 'AutoAugment',\n",
       " 'AutoAugmentPolicy',\n",
       " 'CenterCrop',\n",
       " 'ColorJitter',\n",
       " 'Compose',\n",
       " 'ConvertImageDtype',\n",
       " 'ElasticTransform',\n",
       " 'FiveCrop',\n",
       " 'GaussianBlur',\n",
       " 'Grayscale',\n",
       " 'InterpolationMode',\n",
       " 'Lambda',\n",
       " 'LinearTransformation',\n",
       " 'Normalize',\n",
       " 'PILToTensor',\n",
       " 'Pad',\n",
       " 'RandAugment',\n",
       " 'RandomAdjustSharpness',\n",
       " 'RandomAffine',\n",
       " 'RandomApply',\n",
       " 'RandomAutocontrast',\n",
       " 'RandomChoice',\n",
       " 'RandomCrop',\n",
       " 'RandomEqualize',\n",
       " 'RandomErasing',\n",
       " 'RandomGrayscale',\n",
       " 'RandomHorizontalFlip',\n",
       " 'RandomInvert',\n",
       " 'RandomOrder',\n",
       " 'RandomPerspective',\n",
       " 'RandomPosterize',\n",
       " 'RandomResizedCrop',\n",
       " 'RandomRotation',\n",
       " 'RandomSolarize',\n",
       " 'RandomVerticalFlip',\n",
       " 'Resize',\n",
       " 'TenCrop',\n",
       " 'ToPILImage',\n",
       " 'ToTensor',\n",
       " 'TrivialAugmentWide',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " '_functional_pil',\n",
       " '_functional_tensor',\n",
       " '_presets',\n",
       " 'autoaugment',\n",
       " 'functional',\n",
       " 'transforms']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(transforms)    # List of funcs we can use on our images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1ce44f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_tensor = transforms.ToTensor()          # We have converted image to tensor\n",
    "image_tensor = to_tensor(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "79252325",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(image_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d61dca68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 32, 32])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_tensor.shape              # Size of image after transforming it to tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ea1b0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We transformed just an image earlier but now if we want to transform whole data, we first\n",
    "# a variable\n",
    "\n",
    "tensor_cifar10 = datasets.CIFAR10(data_path, train=True, download=False, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d5691ec5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_cifar10[0][0].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "63a11273",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_tensor.min()  #transformation has also normalized the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5b5f76d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_tensor.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a41d83",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Invalid shape (3, 32, 32) for image data",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(tensor_cifar10[\u001b[38;5;241m100\u001b[39m][\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[1;32mF:\\Anaconda\\Lib\\site-packages\\matplotlib\\pyplot.py:2695\u001b[0m, in \u001b[0;36mimshow\u001b[1;34m(X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, interpolation_stage, filternorm, filterrad, resample, url, data, **kwargs)\u001b[0m\n\u001b[0;32m   2689\u001b[0m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[38;5;241m.\u001b[39mimshow)\n\u001b[0;32m   2690\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mimshow\u001b[39m(\n\u001b[0;32m   2691\u001b[0m         X, cmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m, aspect\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, interpolation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   2692\u001b[0m         alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, vmin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, vmax\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, origin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, extent\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   2693\u001b[0m         interpolation_stage\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, filternorm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, filterrad\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4.0\u001b[39m,\n\u001b[0;32m   2694\u001b[0m         resample\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, url\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m-> 2695\u001b[0m     __ret \u001b[38;5;241m=\u001b[39m gca()\u001b[38;5;241m.\u001b[39mimshow(\n\u001b[0;32m   2696\u001b[0m         X, cmap\u001b[38;5;241m=\u001b[39mcmap, norm\u001b[38;5;241m=\u001b[39mnorm, aspect\u001b[38;5;241m=\u001b[39maspect,\n\u001b[0;32m   2697\u001b[0m         interpolation\u001b[38;5;241m=\u001b[39minterpolation, alpha\u001b[38;5;241m=\u001b[39malpha, vmin\u001b[38;5;241m=\u001b[39mvmin,\n\u001b[0;32m   2698\u001b[0m         vmax\u001b[38;5;241m=\u001b[39mvmax, origin\u001b[38;5;241m=\u001b[39morigin, extent\u001b[38;5;241m=\u001b[39mextent,\n\u001b[0;32m   2699\u001b[0m         interpolation_stage\u001b[38;5;241m=\u001b[39minterpolation_stage,\n\u001b[0;32m   2700\u001b[0m         filternorm\u001b[38;5;241m=\u001b[39mfilternorm, filterrad\u001b[38;5;241m=\u001b[39mfilterrad, resample\u001b[38;5;241m=\u001b[39mresample,\n\u001b[0;32m   2701\u001b[0m         url\u001b[38;5;241m=\u001b[39murl, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m: data} \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m {}),\n\u001b[0;32m   2702\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   2703\u001b[0m     sci(__ret)\n\u001b[0;32m   2704\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m __ret\n",
      "File \u001b[1;32mF:\\Anaconda\\Lib\\site-packages\\matplotlib\\__init__.py:1442\u001b[0m, in \u001b[0;36m_preprocess_data.<locals>.inner\u001b[1;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1439\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m   1440\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(ax, \u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m   1441\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1442\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(ax, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mmap\u001b[39m(sanitize_sequence, args), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1444\u001b[0m     bound \u001b[38;5;241m=\u001b[39m new_sig\u001b[38;5;241m.\u001b[39mbind(ax, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1445\u001b[0m     auto_label \u001b[38;5;241m=\u001b[39m (bound\u001b[38;5;241m.\u001b[39marguments\u001b[38;5;241m.\u001b[39mget(label_namer)\n\u001b[0;32m   1446\u001b[0m                   \u001b[38;5;129;01mor\u001b[39;00m bound\u001b[38;5;241m.\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mget(label_namer))\n",
      "File \u001b[1;32mF:\\Anaconda\\Lib\\site-packages\\matplotlib\\axes\\_axes.py:5665\u001b[0m, in \u001b[0;36mAxes.imshow\u001b[1;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, interpolation_stage, filternorm, filterrad, resample, url, **kwargs)\u001b[0m\n\u001b[0;32m   5657\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_aspect(aspect)\n\u001b[0;32m   5658\u001b[0m im \u001b[38;5;241m=\u001b[39m mimage\u001b[38;5;241m.\u001b[39mAxesImage(\u001b[38;5;28mself\u001b[39m, cmap\u001b[38;5;241m=\u001b[39mcmap, norm\u001b[38;5;241m=\u001b[39mnorm,\n\u001b[0;32m   5659\u001b[0m                       interpolation\u001b[38;5;241m=\u001b[39minterpolation, origin\u001b[38;5;241m=\u001b[39morigin,\n\u001b[0;32m   5660\u001b[0m                       extent\u001b[38;5;241m=\u001b[39mextent, filternorm\u001b[38;5;241m=\u001b[39mfilternorm,\n\u001b[0;32m   5661\u001b[0m                       filterrad\u001b[38;5;241m=\u001b[39mfilterrad, resample\u001b[38;5;241m=\u001b[39mresample,\n\u001b[0;32m   5662\u001b[0m                       interpolation_stage\u001b[38;5;241m=\u001b[39minterpolation_stage,\n\u001b[0;32m   5663\u001b[0m                       \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m-> 5665\u001b[0m im\u001b[38;5;241m.\u001b[39mset_data(X)\n\u001b[0;32m   5666\u001b[0m im\u001b[38;5;241m.\u001b[39mset_alpha(alpha)\n\u001b[0;32m   5667\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m im\u001b[38;5;241m.\u001b[39mget_clip_path() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   5668\u001b[0m     \u001b[38;5;66;03m# image does not already have clipping set, clip to axes patch\u001b[39;00m\n",
      "File \u001b[1;32mF:\\Anaconda\\Lib\\site-packages\\matplotlib\\image.py:710\u001b[0m, in \u001b[0;36m_ImageBase.set_data\u001b[1;34m(self, A)\u001b[0m\n\u001b[0;32m    706\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_A \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_A[:, :, \u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    708\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_A\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[0;32m    709\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_A\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_A\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m4\u001b[39m]):\n\u001b[1;32m--> 710\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid shape \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m for image data\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    711\u001b[0m                     \u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_A\u001b[38;5;241m.\u001b[39mshape))\n\u001b[0;32m    713\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_A\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[0;32m    714\u001b[0m     \u001b[38;5;66;03m# If the input data has values outside the valid range (after\u001b[39;00m\n\u001b[0;32m    715\u001b[0m     \u001b[38;5;66;03m# normalisation), we issue a warning and then clip X to the bounds\u001b[39;00m\n\u001b[0;32m    716\u001b[0m     \u001b[38;5;66;03m# - otherwise casting wraps extreme values, hiding outliers and\u001b[39;00m\n\u001b[0;32m    717\u001b[0m     \u001b[38;5;66;03m# making reliable interpretation impossible.\u001b[39;00m\n\u001b[0;32m    718\u001b[0m     high \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m255\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39missubdtype(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_A\u001b[38;5;241m.\u001b[39mdtype, np\u001b[38;5;241m.\u001b[39minteger) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;31mTypeError\u001b[0m: Invalid shape (3, 32, 32) for image data"
     ]
    }
   ],
   "source": [
    "plt.imshow(tensor_cifar10[100][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1ecc32e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Now we will use permute command and add height, width and channel of image\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(tensor_cifar10[\u001b[38;5;241m100\u001b[39m][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mpermute[\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m0\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "# Now we will use permute command and add height, width and channel of image\n",
    "\n",
    "plt.imshow(tensor_cifar10[100][0].permute[1,2,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ecb70eb",
   "metadata": {},
   "source": [
    "#### Because we are going to work with the whole dataset, we are going to stack all the images. We can achieve this by using the torch.stack() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "361aa41c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m imgs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack([img_t \u001b[38;5;28;01mfor\u001b[39;00m img_t, _ \u001b[38;5;129;01min\u001b[39;00m tensor_transformed], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "imgs = torch.stack([img_t for img_t, _ in tensor_transformed], dim=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3dfe46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
